{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9dee8e2-9d62-45c4-99a6-47ca2da306aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d923e5b-6309-44f1-918d-79a3c8cb2bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# === Configuration ===\n",
    "RAW_ROOT = \"/scratch/users/dtran/croptype/dataset/TimeSen2Crop\"\n",
    "SAVE_DIR = \"./\"\n",
    "N_BANDS = 9\n",
    "N_MONTHS = 12\n",
    "BAND_INDICES = list(range(9))  # B1-B9 → B2-B12\n",
    "FLAG_COL = 'Flag'\n",
    "TRAIN_TILES = ['32TNT', '32TPT', '32TQT', '33TUM', '33TUN', '33TVM', '33TVN',\n",
    "               '33TWM', '33TXN', '33UUP', '33UWP', '33UWQ', '33UXP']\n",
    "VAL_TILE = ['33TWN']\n",
    "TEST_TILE = ['33UVP']\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfaec57-e741-439f-9e60-11fbce22ed2e",
   "metadata": {},
   "source": [
    "# Preprocessing dataset\n",
    "\n",
    "+ Convert to 12 monthly composites using the median of clear pixels.\n",
    "\n",
    "+ Remove cloudy/snowy/shadowed values.\n",
    "\n",
    "+ If no clear value exists in a month, that month’s data is set to zero.\n",
    "\n",
    "Output (data for train, test, and validation sets):\n",
    "\n",
    "+ Clean data\n",
    "    \n",
    "+ Labels for each sample (each sample (pixel) belongs to which class: 0, ..., 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a19d0eda-7902-462d-a903-a86fd7dd8621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32TNT samples: 100%|███████████████████████████████████████████████████████████████████| 21801/21801 [01:00<00:00, 361.92it/s]\n",
      "32TQT samples: 100%|███████████████████████████████████████████████████████████████████| 23084/23084 [01:03<00:00, 361.51it/s]\n",
      "32TPT samples: 100%|███████████████████████████████████████████████████████████████████| 24532/24532 [01:06<00:00, 367.34it/s]\n",
      "33TUM samples: 100%|███████████████████████████████████████████████████████████████████| 26017/26017 [01:10<00:00, 371.18it/s]\n",
      "33TUN samples: 100%|███████████████████████████████████████████████████████████████████| 31162/31162 [01:19<00:00, 391.64it/s]\n",
      "33TVN samples: 100%|███████████████████████████████████████████████████████████████████| 35637/35637 [01:26<00:00, 411.64it/s]\n",
      "33TVM samples: 100%|███████████████████████████████████████████████████████████████████| 45293/45293 [01:40<00:00, 450.63it/s]\n",
      "33TWM samples: 100%|███████████████████████████████████████████████████████████████████| 58786/58786 [01:56<00:00, 503.71it/s]\n",
      "33TXN samples: 100%|███████████████████████████████████████████████████████████████████| 59552/59552 [01:57<00:00, 508.77it/s]\n",
      "33UUP samples: 100%|███████████████████████████████████████████████████████████████████| 93044/93044 [02:21<00:00, 655.62it/s]\n",
      "33UWQ samples: 100%|███████████████████████████████████████████████████████████████████| 96403/96403 [02:23<00:00, 670.26it/s]\n",
      "33UXP samples: 100%|█████████████████████████████████████████████████████████████████| 130468/130468 [02:34<00:00, 845.20it/s]\n",
      "33UWP samples: 100%|████████████████████████████████████████████████████████████████| 177064/177064 [02:40<00:00, 1104.91it/s]\n",
      "Processing train tiles: 13it [02:51, 13.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train: 822843 samples to train_X.pt / train_y.pt\n",
      "Saved train metadata to train_metadata1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33TWN samples: 100%|████████████████████████████████████████████████████████████████| 116369/116369 [00:24<00:00, 4802.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved val: 116369 samples to val_X.pt / val_y.pt\n",
      "Saved val metadata to val_metadata1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33UVP samples: 100%|████████████████████████████████████████████████████████████████| 133419/133419 [00:27<00:00, 4897.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test: 133419 samples to test_X.pt / test_y.pt\n",
      "Saved test metadata to test_metadata1.csv\n"
     ]
    }
   ],
   "source": [
    "# === Helper Functions ===\n",
    "def extract_monthly_median(data: pd.DataFrame, dates: list) -> np.ndarray:\n",
    "    reflectance = data.iloc[:, BAND_INDICES].values\n",
    "    flags = data[FLAG_COL].values\n",
    "    months = [datetime.strptime(str(d), \"%Y%m%d\").month for d in dates]\n",
    "    monthly = np.zeros((N_MONTHS, N_BANDS), dtype=np.float32)\n",
    "\n",
    "    for m in range(1, 13):\n",
    "        idx = [i for i, mo in enumerate(months) if mo == m and flags[i] == 0]\n",
    "        if idx:\n",
    "            monthly[m - 1] = np.median(reflectance[idx], axis=0)\n",
    "        else:\n",
    "            monthly[m - 1] = 0.0\n",
    "    return monthly\n",
    "\n",
    "def build_label_map(root: str) -> dict:\n",
    "    label_map = {}\n",
    "    for tile in sorted(os.listdir(root)):\n",
    "        tile_path = os.path.join(root, tile)\n",
    "        if not os.path.isdir(tile_path): continue\n",
    "        for cls in sorted(os.listdir(tile_path)):\n",
    "            if cls.isdigit() and cls not in label_map:\n",
    "                label_map[cls] = int(cls)\n",
    "    return label_map\n",
    "\n",
    "def process_sample(cls_path, file, date_list, label):\n",
    "    try:\n",
    "        df = pd.read_csv(os.path.join(cls_path, file))\n",
    "        if len(df) != len(date_list):\n",
    "            return None\n",
    "        result = extract_monthly_median(df, date_list)\n",
    "        return result, label\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {cls_path}/{file}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_sample_wrapper(args):\n",
    "    return process_sample(*args)\n",
    "\n",
    "def process_tile_parallel(tile: str, label_map: dict) -> list:\n",
    "    tile_data = []\n",
    "    metadata = []\n",
    "    tile_path = os.path.join(RAW_ROOT, tile)\n",
    "    if not os.path.isdir(tile_path): return tile_data\n",
    "\n",
    "    dates_path = os.path.join(tile_path, \"dates.csv\")\n",
    "    if not os.path.exists(dates_path):\n",
    "        print(f\"Missing {dates_path}, skipping...\")\n",
    "        return tile_data\n",
    "    try:\n",
    "        date_list = pd.read_csv(dates_path)[\"acquisition_date\"].tolist()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not read dates.csv in {tile}: {e}\")\n",
    "        return tile_data\n",
    "\n",
    "    tasks = []\n",
    "    for cls in sorted(os.listdir(tile_path)):\n",
    "        cls_path = os.path.join(tile_path, cls)\n",
    "        if not os.path.isdir(cls_path) or not cls.isdigit():\n",
    "            continue\n",
    "        label = label_map[cls]\n",
    "        for file in sorted(os.listdir(cls_path)):\n",
    "            if file.endswith(\".csv\"):\n",
    "                tasks.append((cls_path, file, date_list, label))\n",
    "                metadata.append((tile, label, file))\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=16) as executor:\n",
    "        for result in tqdm(executor.map(process_sample_wrapper, tasks),\n",
    "                           total=len(tasks), desc=f\"{tile} samples\"):\n",
    "            if result is not None:\n",
    "                tile_data.append(result)\n",
    "    return tile_data, metadata\n",
    "\n",
    "def process_split(split_name, tiles, label_map):\n",
    "    all_data, all_labels = [], []\n",
    "    all_metadata = []\n",
    "    if len(tiles) > 1:\n",
    "        # Parallelize over tiles\n",
    "        with ProcessPoolExecutor(max_workers=16) as executor:\n",
    "            for tile_data, metadata in tqdm(\n",
    "                executor.map(process_tile_parallel, tiles, [label_map]*len(tiles)),\n",
    "                desc=f\"Processing {split_name} tiles\"\n",
    "            ):\n",
    "                for result, label in tile_data:\n",
    "                    all_data.append(result)\n",
    "                    all_labels.append(label)\n",
    "                all_metadata.append(metadata)\n",
    "    else:\n",
    "        # Single tile — still use ProcessPoolExecutor but show sample progress\n",
    "        tile_data, metadata = process_tile_parallel(tiles[0], label_map)\n",
    "        for result, label in tile_data:\n",
    "            all_data.append(result)\n",
    "            all_labels.append(label)\n",
    "        all_metadata.append(metadata)\n",
    "\n",
    "    X = torch.tensor(np.array(all_data), dtype=torch.float32)\n",
    "    y = torch.tensor(np.array(all_labels), dtype=torch.long)\n",
    "    torch.save(X, os.path.join(SAVE_DIR, f\"{split_name}_X.pt\"))\n",
    "    torch.save(y, os.path.join(SAVE_DIR, f\"{split_name}_y.pt\"))\n",
    "    print(f\"Saved {split_name}: {X.shape[0]} samples to {split_name}_X.pt / {split_name}_y.pt\")\n",
    "\n",
    "    metadata_flat = [item for sublist in all_metadata for item in sublist]  # Flatten the list of lists\n",
    "    metadata_df = pd.DataFrame(metadata_flat, columns=[\"tile\", \"label\", \"file\"])\n",
    "    metadata_df.to_csv(os.path.join(SAVE_DIR, f\"{split_name}_metadata.csv\"), index=False)\n",
    "    print(f\"Saved {split_name} metadata to {split_name}_metadata.csv\")\n",
    "\n",
    "\n",
    "# === Run All ===\n",
    "if __name__ == \"__main__\":\n",
    "    label_map = build_label_map(RAW_ROOT)\n",
    "    process_split(\"train\", TRAIN_TILES, label_map)\n",
    "    process_split(\"val\", VAL_TILE, label_map)\n",
    "    process_split(\"test\", TEST_TILE, label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeefab6-889b-41fe-88b2-d0152aec4f80",
   "metadata": {},
   "source": [
    "# Checking Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b969119-08c8-4885-9260-0a779db397d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([822843, 12, 9]) torch.Size([822843]) (822843, 3)\n",
      "Sample data: tensor([[1583.0000, 1662.0000, 1909.0000, 2089.0000, 2420.0000, 2493.0000,\n",
      "         2745.0000, 1934.0000, 1819.0000],\n",
      "        [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000,    0.0000,    0.0000],\n",
      "        [ 595.5000,  953.0000, 1248.5000, 1818.0000, 2900.0000, 3278.5000,\n",
      "         3807.5000, 3476.0000, 2169.5000],\n",
      "        [ 397.5000,  709.5000,  620.5000, 1206.0000, 2818.0000, 3166.5000,\n",
      "         3530.0000, 2115.5000, 1058.5000],\n",
      "        [ 382.0000,  821.0000,  437.0000, 1367.0000, 4502.0000, 5357.0000,\n",
      "         5826.0000, 2827.0000, 1261.0000],\n",
      "        [ 385.0000,  792.0000,  565.0000, 1394.0000, 3696.0000, 4280.0000,\n",
      "         4847.0000, 2754.0000, 1400.0000],\n",
      "        [ 391.5000,  700.5000,  503.5000, 1210.5000, 3109.0000, 3710.5000,\n",
      "         4359.0000, 2536.0000, 1203.5000],\n",
      "        [ 335.5000,  704.0000,  469.5000, 1448.0000, 3730.0000, 4315.0000,\n",
      "         4781.5000, 2609.5000, 1237.5000],\n",
      "        [ 442.0000,  907.0000,  844.0000, 1690.0000, 3453.0000, 3970.0000,\n",
      "         4810.0000, 3597.0000, 1799.0000],\n",
      "        [ 449.0000,  923.0000,  956.0000, 1919.0000, 3722.0000, 4457.0000,\n",
      "         5448.0000, 3804.0000, 2011.0000],\n",
      "        [1405.0000,  902.0000,  552.0000,  427.0000,  388.0000,  377.0000,\n",
      "          328.0000,    0.0000,    0.0000]])\n",
      "Labels: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Example metadata: tile     32TNT\n",
      "label        1\n",
      "file     0.csv\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.load(\"train_X.pt\")\n",
    "y_train = torch.load(\"train_y.pt\")\n",
    "metadata_df = pd.read_csv(\"train_metadata.csv\")\n",
    "\n",
    "# Shape of train dataset: [N, n_months, n_bands], there are N samples, each sample is a n_months x n_bands matrix showing the median values of each band across each month acquired\n",
    "print(\"Shape:\", X_train.shape, y_train.shape, metadata_df.shape)\n",
    "#Show example of data\n",
    "print(\"Sample data:\", X_train[0])#Note: months in the output (1/2018, 2/2018, ..., 7/2018, 9/2017, ..., 12/2017) is arranged in different order from dates.csv file\n",
    "# Show example of labels\n",
    "print(\"Labels:\", y_train[:10])\n",
    "print(\"Example metadata:\", metadata_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102dde44-2efe-467a-aedf-94047f492741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "croptypeenv",
   "language": "python",
   "name": "croptypeenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
